{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport numpy as np\nimport nibabel as nib\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"id":"b9N2ieW1ARGh","executionInfo":{"status":"ok","timestamp":1624251232676,"user_tz":-330,"elapsed":1009,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:02:58.521625Z","iopub.execute_input":"2021-06-22T01:02:58.521990Z","iopub.status.idle":"2021-06-22T01:03:04.393555Z","shell.execute_reply.started":"2021-06-22T01:02:58.521913Z","shell.execute_reply":"2021-06-22T01:03:04.392776Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\"\"\"3D UNET model for Tensorflow-Keras.\"\"\"\n\ndef conv_block(x, filters, maxpool=False):\n    x = layers.Conv3D(filters=filters, kernel_size=(3, 3, 3), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    y = layers.Conv3D(filters=filters, kernel_size=(3, 3, 3), padding='same')(x)\n    y = layers.BatchNormalization()(y)\n    y = layers.Activation('relu')(y)\n    if maxpool:\n        y = layers.MaxPooling3D(pool_size=(2, 2, 2))(y)\n    return x, y\n    \n\ndef compress_block(x):\n    x = layers.Conv3D(filters=128, kernel_size=(3, 3, 3), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv3D(filters=32, kernel_size=(1, 1, 1), padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    return x\n\n\ndef decode_block(x, filters, down_conn):\n    deconv = layers.Conv3DTranspose(filters=filters, kernel_size=(2, 2, 2), strides=(2, 2, 2))(x)\n    deconv = layers.BatchNormalization()(deconv)\n    deconv = x = layers.Activation('relu')(deconv)\n    _, conv_1 = conv_block(deconv, filters=filters)\n    concat = layers.Concatenate(axis=-1)([down_conn, conv_1])\n    conv_2 = layers.Conv3D(filters=filters, kernel_size=(1, 1, 1), padding='same')(concat)\n    conv_2 = layers.BatchNormalization()(conv_2)\n    conv_2 = layers.Activation('relu')(conv_2)\n    return conv_2\n\n\ndef unet_3d():\n    input_layer = keras.Input(shape=(128, 128, 96, 1)) \n    \n    conn1, down1 = conv_block(input_layer, filters=16)\n    conn2, down2 = conv_block(down1, filters=16, maxpool=True)\n    conn3, down3 = conv_block(down2, filters=32, maxpool=True)\n    conn4, down4 = conv_block(down3, filters=64, maxpool=True)\n    conn5, down5 = conv_block(down4, filters=128, maxpool=True)\n    \n    compress1 = compress_block(down5)\n    compress2 = compress_block(compress1)\n    compress3 = compress_block(compress2)\n    \n    decode1 = decode_block(compress3, filters=128, down_conn=conn5)\n    decode2 = decode_block(decode1, filters=64, down_conn=conn4)\n    decode3 = decode_block(decode2, filters=32, down_conn=conn3)\n    decode4 = decode_block(decode3, filters=16, down_conn=conn2)\n    \n    output = layers.Conv3D(filters=16, kernel_size=(1, 1, 1), padding='same')(decode4)\n    output = layers.BatchNormalization()(output)\n    output = layers.Activation('relu')(output)\n    output = layers.Conv3DTranspose(filters=16, kernel_size=(2, 2, 2), padding='same')(output)\n    output = layers.BatchNormalization()(output)\n    output = layers.Activation('relu')(output)\n    output = layers.concatenate([conn1, output], axis=-1)\n    output = layers.Conv3D(filters=2, kernel_size=(1, 1, 1), padding='same', activation='softmax')(output)\n    \n    model = keras.Model(inputs=input_layer, outputs=output)\n    return model","metadata":{"id":"jUxf5pzpqa-Q","executionInfo":{"status":"ok","timestamp":1624251236416,"user_tz":-330,"elapsed":689,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:05.664180Z","iopub.execute_input":"2021-06-22T01:03:05.664504Z","iopub.status.idle":"2021-06-22T01:03:05.683297Z","shell.execute_reply.started":"2021-06-22T01:03:05.664473Z","shell.execute_reply":"2021-06-22T01:03:05.682448Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = unet_3d()\n# model.output\n# model.summary()","metadata":{"id":"SUYR3jabrR6r","executionInfo":{"status":"ok","timestamp":1624251242920,"user_tz":-330,"elapsed":6057,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:07.282460Z","iopub.execute_input":"2021-06-22T01:03:07.282778Z","iopub.status.idle":"2021-06-22T01:03:10.526501Z","shell.execute_reply.started":"2021-06-22T01:03:07.282748Z","shell.execute_reply":"2021-06-22T01:03:10.525746Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"skull_stripping_unet_3d_soft_dice_loss.h5\"\ninitial_learning_rate = 0.003","metadata":{"id":"oEBs_jJD96oc","executionInfo":{"status":"ok","timestamp":1624251254272,"user_tz":-330,"elapsed":409,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:11.690327Z","iopub.execute_input":"2021-06-22T01:03:11.690647Z","iopub.status.idle":"2021-06-22T01:03:11.694279Z","shell.execute_reply.started":"2021-06-22T01:03:11.690619Z","shell.execute_reply":"2021-06-22T01:03:11.693421Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n       initial_learning_rate,\n       decay_steps=1000,\n       decay_rate=0.96,\n       staircase=True,\n   )\n\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path,\n        monitor='val_loss',\n        verbose=1,\n        save_best_only=True,\n        mode='min',\n    )\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',  \n    patience=5, \n    verbose=1)","metadata":{"id":"Eeg6465atU0z","executionInfo":{"status":"ok","timestamp":1624251254880,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:12.915128Z","iopub.execute_input":"2021-06-22T01:03:12.915460Z","iopub.status.idle":"2021-06-22T01:03:12.921720Z","shell.execute_reply.started":"2021-06-22T01:03:12.915430Z","shell.execute_reply":"2021-06-22T01:03:12.920778Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def dice_coefficient(y_true, \n                     y_pred, \n                     axis=(1, 2, 3), \n                     epsilon=0.00001):\n    \"\"\"\n    Compute mean dice coefficient over all abnormality classes.\n\n    Args:\n        y_true (Tensorflow tensor): tensor of ground truth values for all classes.\n                                    shape: (num_classes, x_dim, y_dim, z_dim)\n        y_pred (Tensorflow tensor): tensor of predictions for all classes.\n                                    shape: (num_classes, x_dim, y_dim, z_dim)\n        axis (tuple): spatial axes to sum over when computing numerator and\n                      denominator of dice coefficient.\n                      Hint: pass this as the 'axis' argument to the K.sum\n                            and K.mean functions.\n        epsilon (float): small constant add to numerator and denominator to\n                        avoid divide by 0 errors.\n    Returns:\n        dice_coefficient (float): computed value of dice coefficient.     \n    \"\"\"\n    \n    dice_numerator = 2. * tf.reduce_sum(y_true * y_pred, axis=axis) + epsilon\n    dice_denominator = tf.reduce_sum(y_true, axis=axis) + tf.reduce_sum(y_pred, axis=axis) + epsilon\n    dice_coefficient = tf.reduce_mean((dice_numerator)/(dice_denominator))\n    \n    return dice_coefficient","metadata":{"id":"1nYE4pNu63wU","execution":{"iopub.status.busy":"2021-06-22T01:03:13.838093Z","iopub.execute_input":"2021-06-22T01:03:13.838412Z","iopub.status.idle":"2021-06-22T01:03:13.844877Z","shell.execute_reply.started":"2021-06-22T01:03:13.838383Z","shell.execute_reply":"2021-06-22T01:03:13.844040Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def soft_dice_loss(y_true, \n                   y_pred, \n                   axis=(1, 2, 3), \n                   epsilon=0.00001):\n    \"\"\"\n    Compute mean soft dice loss over all abnormality classes.\n\n    Args:\n        y_true (Tensorflow tensor): tensor of ground truth values for all classes.\n                                    shape: (num_classes, x_dim, y_dim, z_dim)\n        y_pred (Tensorflow tensor): tensor of soft predictions for all classes.\n                                    shape: (num_classes, x_dim, y_dim, z_dim)\n        axis (tuple): spatial axes to sum over when computing numerator and\n                      denominator in formula for dice loss.\n                      Hint: pass this as the 'axis' argument to the K.sum\n                            and K.mean functions.\n        epsilon (float): small constant added to numerator and denominator to\n                        avoid divide by 0 errors.\n    Returns:\n        dice_loss (float): computed value of dice loss.     \n    \"\"\"\n\n    dice_numerator = 2. * tf.reduce_sum(y_true * y_pred, axis=axis) + epsilon\n    dice_denominator = tf.reduce_sum(y_true**2, axis=axis) +tf.reduce_sum(y_pred**2, axis=axis) + epsilon\n    dice_loss = 1 - tf.reduce_mean((dice_numerator)/(dice_denominator))\n\n    return dice_loss","metadata":{"id":"N-cEUwq1cNF3","executionInfo":{"status":"ok","timestamp":1624251257856,"user_tz":-330,"elapsed":17,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:14.620212Z","iopub.execute_input":"2021-06-22T01:03:14.620532Z","iopub.status.idle":"2021-06-22T01:03:14.626835Z","shell.execute_reply.started":"2021-06-22T01:03:14.620503Z","shell.execute_reply":"2021-06-22T01:03:14.625962Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n              loss=soft_dice_loss,#tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy', dice_coefficient])\n\nepochs=30\nhistory = model.fit(train_data, \n                    epochs=epochs,\n                    validation_data=valid_data,\n                    callbacks=[checkpoint_callback, early_stopping])","metadata":{"id":"mFar92wL9J9s","execution":{"iopub.status.busy":"2021-06-22T01:03:52.662526Z","iopub.execute_input":"2021-06-22T01:03:52.662861Z","iopub.status.idle":"2021-06-22T03:32:24.769486Z","shell.execute_reply.started":"2021-06-22T01:03:52.662831Z","shell.execute_reply":"2021-06-22T03:32:24.764154Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/30\n920/920 [==============================] - 1462s 2s/step - loss: 0.1906 - accuracy: 0.9413 - dice_coefficient: 0.7393 - val_loss: 0.1056 - val_accuracy: 0.9695 - val_dice_coefficient: 0.8735\n\nEpoch 00001: val_loss improved from inf to 0.10563, saving model to skull_stripping_unet_3d_soft_dice_loss.h5\nEpoch 2/30\n920/920 [==============================] - 1430s 2s/step - loss: 0.0324 - accuracy: 0.9922 - dice_coefficient: 0.9280 - val_loss: 0.0773 - val_accuracy: 0.9805 - val_dice_coefficient: 0.9010\n\nEpoch 00002: val_loss improved from 0.10563 to 0.07731, saving model to skull_stripping_unet_3d_soft_dice_loss.h5\nEpoch 3/30\n920/920 [==============================] - 1419s 2s/step - loss: 0.0276 - accuracy: 0.9933 - dice_coefficient: 0.9399 - val_loss: 0.1248 - val_accuracy: 0.9776 - val_dice_coefficient: 0.8575\n\nEpoch 00003: val_loss did not improve from 0.07731\nEpoch 4/30\n920/920 [==============================] - 1431s 2s/step - loss: 0.0270 - accuracy: 0.9934 - dice_coefficient: 0.9454 - val_loss: 0.1568 - val_accuracy: 0.9551 - val_dice_coefficient: 0.8274\n\nEpoch 00004: val_loss did not improve from 0.07731\nEpoch 5/30\n920/920 [==============================] - 1419s 2s/step - loss: 0.0229 - accuracy: 0.9945 - dice_coefficient: 0.9506 - val_loss: 0.0717 - val_accuracy: 0.9801 - val_dice_coefficient: 0.9061\n\nEpoch 00005: val_loss improved from 0.07731 to 0.07171, saving model to skull_stripping_unet_3d_soft_dice_loss.h5\nEpoch 6/30\n920/920 [==============================] - 1419s 2s/step - loss: 0.0210 - accuracy: 0.9947 - dice_coefficient: 0.9563 - val_loss: 0.0626 - val_accuracy: 0.9895 - val_dice_coefficient: 0.9200\n\nEpoch 00006: val_loss improved from 0.07171 to 0.06264, saving model to skull_stripping_unet_3d_soft_dice_loss.h5\nEpoch 7/30\n221/920 [======>.......................] - ETA: 17:14 - loss: 0.0175 - accuracy: 0.9957 - dice_coefficient: 0.9640","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-8316614d195b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     callbacks=[checkpoint_callback, early_stopping])\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import math\n# Here, `x_set` is list of path to the images\n# and `y_set` are the associated classes.\n\nclass BrainMRIDataset(tf.keras.utils.Sequence):\n\n    def __init__(self, x_set, y_set, batch_size):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n\n    def read_nifti_file(self, filepath):\n      volume = nib.load(filepath).get_fdata()\n      volume = np.array(volume)\n      return volume\n\n\n    def __getitem__(self, idx):\n\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        image = [self.read_nifti_file(image_file) for image_file in batch_x]\n        # image = np.rollaxis(image, 0, 3)\n        image = tf.expand_dims(image, axis=-1)\n        label = [self.read_nifti_file(mask_file) for mask_file in batch_y]\n        label = tf.keras.utils.to_categorical(label, 2)\n        # label = np.rollaxis(label, 0, 3)\n        # label = tf.expand_dims(label, axis=0)\n\n        return image, label","metadata":{"id":"OJQLoCOdL_Er","executionInfo":{"status":"ok","timestamp":1624251262395,"user_tz":-330,"elapsed":1089,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:18.751699Z","iopub.execute_input":"2021-06-22T01:03:18.752023Z","iopub.status.idle":"2021-06-22T01:03:18.760050Z","shell.execute_reply.started":"2021-06-22T01:03:18.751977Z","shell.execute_reply":"2021-06-22T01:03:18.759188Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_image_paths = sorted(glob.glob('../input/neuroscience/train/images/*'))\ntrain_mask_paths = sorted(glob.glob('../input/neuroscience/train/masks/*'))\n\nvalid_image_paths = sorted(glob.glob('../input/neuroscience/valid/images/*'))\nvalid_mask_paths = sorted(glob.glob('../input/neuroscience/valid/masks/*'))","metadata":{"id":"Z3CYryMRvPlJ","executionInfo":{"status":"ok","timestamp":1624251268286,"user_tz":-330,"elapsed":5900,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:19.769304Z","iopub.execute_input":"2021-06-22T01:03:19.769639Z","iopub.status.idle":"2021-06-22T01:03:20.064351Z","shell.execute_reply.started":"2021-06-22T01:03:19.769609Z","shell.execute_reply":"2021-06-22T01:03:20.063444Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# !cp -r /content/drive/MyDrive/Patchs .","metadata":{"id":"eD3HVm7BYZ8g","executionInfo":{"status":"ok","timestamp":1624214538625,"user_tz":-330,"elapsed":984416,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:20.521422Z","iopub.execute_input":"2021-06-22T01:03:20.521745Z","iopub.status.idle":"2021-06-22T01:03:20.527876Z","shell.execute_reply.started":"2021-06-22T01:03:20.521714Z","shell.execute_reply":"2021-06-22T01:03:20.527061Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# train_image_paths = sorted(glob.glob('/content/Patchs/train/images/*'))\n# train_mask_paths = sorted(glob.glob('/content/Patchs/train/masks/*'))\n\n# valid_image_paths = sorted(glob.glob('/content/Patchs/valid/images/*'))\n# valid_mask_paths = sorted(glob.glob('/content/Patchs/valid/masks/*'))","metadata":{"id":"gwzNO8KokHaE","executionInfo":{"status":"ok","timestamp":1624214626774,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:20.997031Z","iopub.execute_input":"2021-06-22T01:03:20.997354Z","iopub.status.idle":"2021-06-22T01:03:21.000930Z","shell.execute_reply.started":"2021-06-22T01:03:20.997324Z","shell.execute_reply":"2021-06-22T01:03:20.999784Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data = BrainMRIDataset(train_image_paths, train_mask_paths, 1)\nvalid_data = BrainMRIDataset(valid_image_paths, valid_mask_paths, 1)","metadata":{"id":"fVnIJwT-nSpA","executionInfo":{"status":"ok","timestamp":1624251268305,"user_tz":-330,"elapsed":25,"user":{"displayName":"Rony R.","photoUrl":"","userId":"08800567102376145323"}},"execution":{"iopub.status.busy":"2021-06-22T01:03:21.644320Z","iopub.execute_input":"2021-06-22T01:03:21.644632Z","iopub.status.idle":"2021-06-22T01:03:21.648601Z","shell.execute_reply.started":"2021-06-22T01:03:21.644603Z","shell.execute_reply":"2021-06-22T01:03:21.647622Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"lFjfF7ZEu8NB"},"execution_count":null,"outputs":[]}]}